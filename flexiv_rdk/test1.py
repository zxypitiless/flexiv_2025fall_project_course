#!/usr/bin/env python3
import os
import cv2
import torch
import numpy as np
from ropewrap.unet import UNet

# ===================== é…ç½® =====================
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

CHECKPOINT = "/home/wangbingquan/flexiv_rdk/ropewrap/checkpoints1126/unet_epoch_60.pt"
DATA_DIR = "/home/wangbingquan/flexiv_rdk/ropewrap/data/rgbd_dataset"
OUT_DIR = "/home/wangbingquan/flexiv_rdk/ropewrap/test_output"
os.makedirs(OUT_DIR, exist_ok=True)
# ==================================================

# -------------------- æµ‹è¯•æ•°æ®é›†ï¼ˆæ— æ ‡ç­¾ï¼‰ --------------------
class RodDatasetTest:
    def __init__(self, root):
        self.root = root
        self.scenes = sorted([d for d in os.listdir(root) if d.isdigit()])

    def __len__(self):
        return len(self.scenes)

    def __getitem__(self, idx):
        scene = self.scenes[idx]
        folder = os.path.join(self.root, scene)

        # load RGB
        rgb_path = os.path.join(folder, "rgb.png")
        rgb = cv2.imread(rgb_path)
        if rgb is None:
            raise RuntimeError(f"æ— æ³•è¯»å– {rgb_path}")
        rgb = cv2.cvtColor(rgb, cv2.COLOR_BGR2RGB)

        # load depth (å¯é€‰ï¼Œç”¨äºåç»­æ‰©å±•)
        depth_path = os.path.join(folder, "depth.npy")
        depth = np.load(depth_path)

        return rgb, depth

# -------------------- è½½å…¥æ¨¡å‹ --------------------
def load_model():
    print("ğŸ” åŠ è½½æ¨¡å‹ä¸­:", CHECKPOINT)
    ckpt = torch.load(CHECKPOINT, map_location=DEVICE)

    state_dict = ckpt["model"]
    model = UNet(n_channels=3, n_classes=3)
    model.load_state_dict(state_dict)
    model.to(DEVICE)
    model.eval()
    print("âœ… æ¨¡å‹åŠ è½½å®Œæˆ")
    return model

# -------------------- æ¨ç†å‡½æ•° --------------------
def predict_mask(model, rgb):
    """ è¾“å…¥ RGB å›¾åƒï¼Œè¾“å‡ºæ¨¡å‹é¢„æµ‹ mask """
    img = rgb.astype(np.float32) / 255.0
    img = img.transpose(2, 0, 1)  # HWC â†’ CHW
    img_tensor = torch.from_numpy(img).unsqueeze(0).to(DEVICE)

    with torch.no_grad():
        pred = model(img_tensor)
        pred = torch.sigmoid(pred)
        pred_mask = (pred > 0.5).cpu().numpy()[0]  # shape (3,H,W)
    return pred_mask

# -------------------- å¯è§†åŒ– --------------------
def visualize_mask(rgb, pred_mask, save_path):
    """æ ¹æ®é¢„æµ‹çš„ mask ç”¨çº¢ç»¿è“æ ‡å‡ºä¸‰æ ¹æ†"""
    rgb_vis = rgb.copy()

    colors = [
        (0, 0, 255),   # çº¢
        (0, 255, 0),   # ç»¿
        (255, 0, 0)    # è“
    ]

    for i in range(3):
        mask = pred_mask[i]
        mask = mask.astype(np.uint8)
        color_layer = np.zeros_like(rgb)
        color_layer[:, :, 0] = colors[i][2]
        color_layer[:, :, 1] = colors[i][1]
        color_layer[:, :, 2] = colors[i][0]

        rgb_vis = np.where(mask[..., None] > 0, 
                           0.7 * rgb_vis + 0.3 * color_layer,
                           rgb_vis)
    cv2.imwrite(save_path, rgb_vis)
    print(f"âœ” å·²ä¿å­˜å¯è§†åŒ–: {save_path}")

# -------------------- ä¸»å‡½æ•° --------------------
def main():
    model = load_model()

    dataset = RodDatasetTest(DATA_DIR)
    print(f"æ•°æ®é›†å¤§å°: {len(dataset)} ç»„")

    for idx in range(len(dataset)):
        rgb, depth = dataset[idx]

        pred_mask = predict_mask(model, rgb)

        save_path = os.path.join(OUT_DIR, f"vis_{idx:02d}.png")
        visualize_mask(rgb, pred_mask, save_path)

    print("\nğŸ‰ å…¨éƒ¨æµ‹è¯•å®Œæˆï¼Œç»“æœä¿å­˜åœ¨ï¼š", OUT_DIR)

if __name__ == "__main__":
    main()
